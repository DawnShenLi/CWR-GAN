{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy.random\n",
    "SEED = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "numpy.random.seed(SEED)\n",
    "numpy.random.set_state(numpy.random.RandomState(SEED).get_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "import os, shutil, matplotlib, matplotlib.pyplot as plt, pandas as pd, tensorflow as tf\n",
    "import ml_toolkit.tensorflow_constructions as tfc\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "from translator_wgan import TranslatorWGAN\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "matplotlib.rcParams['animation.writer'] = 'avconv'\n",
    "matplotlib.rcParams['animation.html'] = 'html5'\n",
    "matplotlib.rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '/scratch/mmd/project_run_files/modality_translation/nan_debugging/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def columns(d): return d.iloc[:, 0], d.iloc[:, 1] if type(d) is pd.DataFrame else d[:, 0], d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    source_data,\n",
    "    target_data,\n",
    "    joint = False,\n",
    "    opts = None,\n",
    "    exp_dir = BASE_DIR,\n",
    "    model_name = '',\n",
    "    reset=True,\n",
    "    clear_dir=False,\n",
    "): \n",
    "    siil = []\n",
    "    assert model_name != '', \"Must provide a model name.\"\n",
    "    if reset: tf.reset_default_graph()\n",
    "\n",
    "    save_dir = os.path.join(exp_dir, model_name)\n",
    "    \n",
    "    print(save_dir, os.path.isdir(save_dir))\n",
    "    if clear_dir and os.path.isdir(save_dir): shutil.rmtree(save_dir)\n",
    "    if not os.path.isdir(save_dir): os.mkdir(save_dir)\n",
    "        \n",
    "    source_paired, source_unpaired, source_test = source_data                                          \n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "    \n",
    "    side_info_paired = None                                                      \n",
    "    side_info_source_unpaired = None                                           \n",
    "    side_info_target_unpaired = None                                           \n",
    "    side_info_test = None                                                          \n",
    "    return TranslatorWGAN(                                                                                    \n",
    "        source_paired_df             = source_paired,                                                      \n",
    "        target_paired_df             = target_paired,                                                      \n",
    "        source_unpaired_df           = source_unpaired if joint else source_unpaired.iloc[0:0],            \n",
    "        target_unpaired_df           = target_unpaired if joint else target_unpaired.iloc[0:0],            \n",
    "        side_info_paired_df          = side_info_paired,                                                   \n",
    "        side_info_source_unpaired_df = side_info_source_unpaired if joint else None,                       \n",
    "        side_info_target_unpaired_df = side_info_target_unpaired if joint else None,                       \n",
    "        save_dir                     = save_dir,                                                           \n",
    "        **opts                                                                                          \n",
    "    )                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(source_data, target_data, only_paired=False):\n",
    "    source_paired, source_unpaired, source_test = source_data\n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "    \n",
    "    handles, labels = [], []\n",
    "    handles.append(plt.scatter(*columns(source_paired), color='r')); labels.append('Source Paired')\n",
    "    handles.append(plt.scatter(*columns(target_paired), color='b')); labels.append('Target Paired')\n",
    "    if not only_paired:\n",
    "        handles.append(plt.scatter(*columns(source_unpaired), color='r', marker='^', alpha=0.01))\n",
    "        handles.append(plt.scatter(*columns(target_unpaired), color='b', marker='^', alpha=0.01))\n",
    "        labels += ['Source Unpaired', 'Target Unpaired']\n",
    "    \n",
    "    plt.xlim([-2, 8])\n",
    "    plt.ylim([-2, 8])\n",
    "    plt.legend(handles, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feed(m, d=None, X=None, Y=None, paired=True):\n",
    "    assert (d is not None) or (X is not None and Y is not None), \"Must provide valid data!\"\n",
    "    if d is None: d = map(lambda a: np.array([a[0], a[1]]).reshape([2, -1]).T, zip(X, Y))\n",
    "    #print \"Source shape: \", d[0].shape, \"Target Shape: \", d[1].shape\n",
    "    return {\n",
    "        m.source_paired: d[0] if paired else np.empty((0, 2)),\n",
    "        m.target_paired: d[1] if paired else np.empty((0, 2)),\n",
    "        m.source_unpaired: np.empty((0, 2)) if paired else d[0],\n",
    "        m.target_unpaired: np.empty((0, 2)) if paired else d[1],\n",
    "        m.side_info_paired:np.empty((len(d[0]), 0)) if paired else np.empty((0, 0)),\n",
    "        m.side_info_source_unpaired: np.empty((0, 0)) if paired else np.empty((len(d[0]), 0)),\n",
    "        m.side_info_target_unpaired: np.empty((0, 0)) if paired else np.empty((len(d[1]), 0)),\n",
    "        #m.dropout_keep_prob: 1.0,\n",
    "        m.training: False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_var(m, vs, f=None):\n",
    "    return m.sess.run([m.graph.get_tensor_by_name(v.name) for v in vs], feed_dict=m.feed() if f is None else f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_critic(source_data, target_data, m, source=False):\n",
    "    source_paired, source_unpaired, source_test = source_data\n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "    \n",
    "    delta = 0.01\n",
    "    x = np.arange(-2, 8, delta)\n",
    "    y = np.arange(-2, 8, delta)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    feed_dict = make_feed(m, X=(X, X), Y=(Y, Y))\n",
    "    source_critic, target_critic = eval_var(m, [m.C_source_real, m.C_target_real], f=feed_dict)\n",
    "    source_critic, target_critic = map(lambda s: s.reshape(X.shape), [source_critic, target_critic])\n",
    "\n",
    "    # Create a simple contour plot with labels using default colors.  The\n",
    "    # inline argument to clabel will control whether the labels are draw\n",
    "    # over the line segments of the contour, removing the lines beneath\n",
    "    # the label\n",
    "    if source: SCS = plt.contour(X, Y, source_critic)\n",
    "    else: TCS = plt.contour(X, Y, target_critic)\n",
    "    if source: plt.clabel(SCS, inline=1, fontsize=10)\n",
    "    else: plt.clabel(TCS, inline=1, fontsize=10)\n",
    "    \n",
    "    if source:\n",
    "        paired_handle = plt.scatter(*columns(source_paired), color='r')\n",
    "        unpaired_handle = plt.scatter(*columns(source_unpaired), color='r', marker='^', alpha=0.01)\n",
    "    else:\n",
    "        paired_handle = plt.scatter(*columns(target_paired), color='b')\n",
    "        unpaired_handle = plt.scatter(*columns(target_unpaired), color='b', marker='^', alpha=0.01)\n",
    "\n",
    "    plt.legend(\n",
    "        #[source_paired_handle, target_paired_handle, source_unpaired_handle, target_unpaired_handle],\n",
    "        [paired_handle, unpaired_handle],\n",
    "        #['Source Paired', 'Target Paired', 'Source Unpaired', 'Target Unpaired'])\n",
    "        ['Paired', 'Unpaired']\n",
    "    )\n",
    "    plt.xlim([-2, 8])\n",
    "    plt.ylim([-2, 8])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_predictions(source_data, target_data, m=None,\n",
    "                     plot_target_predictions=False, plot_source_predictions=True, model_name=''):\n",
    "    source_paired, source_unpaired, source_test = source_data\n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "    \n",
    "    source_joint = pd.concat([source_paired, source_unpaired])\n",
    "    target_joint = pd.concat([target_paired, target_unpaired])\n",
    "\n",
    "    if type(m) == TranslatorWGAN:\n",
    "        predictions_of_source, predictions_of_target, cycle_source, cycle_target = \\\n",
    "                            eval_var(m, [m.F_source, m.G_target, m.G_F_source, m.F_G_target],\n",
    "                                         f=make_feed(m, d=(source_joint, target_joint)))\n",
    "    else:\n",
    "        predictions_of_source = m.predict(pd.concat([source_paired, source_unpaired]))\n",
    "\n",
    "    handles, labels = [], []\n",
    "    handles.append(plt.scatter(*columns(pd.concat([source_paired, source_unpaired])), color='r'))\n",
    "    labels.append('Source')\n",
    "    handles.append(plt.scatter(*columns(pd.concat([target_paired, target_unpaired])), color='b'))\n",
    "    labels.append('Target')\n",
    "    if plot_source_predictions: \n",
    "        handles.append(plt.scatter(*columns(predictions_of_source), color='g', marker='*', alpha=1))\n",
    "        labels.append('Source Predictions (overall)')\n",
    "    if plot_target_predictions and type(m) == TranslatorWGAN:\n",
    "        handles.append(plt.scatter(*columns(predictions_of_target), color='y', marker='*', alpha=1))\n",
    "        labels.append('Target Predictions (overall)')\n",
    "    if plot_source_predictions: \n",
    "        handles.append(plt.scatter(*columns(cycle_source), color='k', marker='*', alpha=1))\n",
    "        labels.append('Source Cycle (overall)')\n",
    "    if plot_target_predictions and type(m) == TranslatorWGAN:\n",
    "        handles.append(plt.scatter(*columns(cycle_target), color='m', marker='*', alpha=1))\n",
    "        labels.append('Target Cycle (overall)')\n",
    "        \n",
    "    plt.legend(handles, labels)\n",
    "    plt.xlim([-2, 8])\n",
    "    plt.ylim([-2, 8])\n",
    "    plt.show()\n",
    "    plt.savefig(model_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(source_data, target_data, m=None, pfx='', model_name = ''):\n",
    "    source_paired, source_unpaired, source_test = source_data\n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "\n",
    "    if type(m) == TranslatorWGAN:\n",
    "        predictions_of_source, cycle_source, cycle_target = eval_var(\n",
    "            m, [m.F_source, m.G_F_source, m.F_G_target], f=make_feed(m, d=(source_test, target_test))\n",
    "        )#[0]\n",
    "        #predictions_of_target = eval_var(m, [m.G_target])[0]\n",
    "        cycle_x = np.mean(np.linalg.norm(cycle_source - source_test, axis=1))\n",
    "        cycle_y = np.mean(np.linalg.norm(cycle_target - target_test, axis=1))\n",
    "        extra = ' {} {}'.format(cycle_x, cycle_y)        \n",
    "    else:\n",
    "        extra = ', R² = %.2f' % m.score(source_paired, target_paired)\n",
    "        predictions_of_source = m.predict(source_test)\n",
    "    \n",
    "    print('%sEuclidean Loss: %.2f%s' % (\n",
    "        pfx + ': ' if pfx != '' else '',\n",
    "        np.mean(\n",
    "            np.linalg.norm(predictions_of_source - target_test.values, axis=1)\n",
    "        ),\n",
    "        extra\n",
    "    ))\n",
    "    \n",
    "    plot_predictions(source_data, target_data, m, plot_target_predictions=True, model_name=model_name)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_data(data, ax, color='b', marker='o', alpha=0.02):\n",
    "    all_data = pd.concat(data)\n",
    "    extent = all_data.max().max() - all_data.min().min()\n",
    "    center = all_data.mean()\n",
    "    \n",
    "    ax.set_xlim((center[0] - extent/2. - 0.7, center[0] + extent/2. + 0.7))\n",
    "    ax.set_ylim((center[1] - extent/2. - 0.7, center[1] + extent/2. + 0.7))\n",
    "    ax.axis('equal')\n",
    "    return ax.scatter(*columns(all_data), color=color, marker=marker, alpha=alpha)\n",
    "\n",
    "def animate(\n",
    "    source_data,\n",
    "    target_data,\n",
    "    model_opts,\n",
    "    source_color='r',\n",
    "    target_color='b',\n",
    "    model_name = 'animation',\n",
    "    step_size = 2,\n",
    "    total_steps = 480,\n",
    "    grid_delta = 0.01,\n",
    "    interval=10,\n",
    "    joint=True\n",
    "):\n",
    "    opts = model_opts.copy()\n",
    "    opts['print_anything'] = False\n",
    "    m = build_model(source_data, target_data, model_name=model_name,\n",
    "                    opts=opts, clear_dir=True, joint=joint)\n",
    "\n",
    "        \n",
    "\n",
    "    # First set up the figure, the axis, and the plot element we want to animate\n",
    "    fig = plt.figure()\n",
    "    source_ax = plt.subplot('121')\n",
    "    target_ax = plt.subplot('122')\n",
    "    source_ax.set_title('Source')\n",
    "    target_ax.set_title('Target')\n",
    "\n",
    "    src_data_hdl = plt_data(source_data, source_ax)\n",
    "    target_data_hdl = plt_data(target_data, target_ax)\n",
    "    \n",
    "    data_feed = make_feed(m, d=(pd.concat(source_data), pd.concat(target_data)))\n",
    "\n",
    "    predictions_of_source, predictions_of_target = eval_var(m, [m.F_source, m.G_target], f=data_feed)\n",
    "\n",
    "    source_predictions_hdl, = target_ax.plot(*columns(predictions_of_source), color='r', marker='o', alpha=0.02)\n",
    "    target_predictions_hdl, = source_ax.plot(*columns(predictions_of_target), color='r', marker='o', alpha=0.02)\n",
    "   \n",
    "    source_grid = np.meshgrid(np.arange(*source_ax.get_xlim(), step=grid_delta),\n",
    "                              np.arange(*source_ax.get_ylim(), step=grid_delta))\n",
    "    target_grid = np.meshgrid(np.arange(*target_ax.get_xlim(), step=grid_delta),\n",
    "                              np.arange(*target_ax.get_ylim(), step=grid_delta))\n",
    "    grid_feed = make_feed(m, X=(source_grid[0], target_grid[0]), Y=(source_grid[1], target_grid[1]), paired=False)\n",
    "    source_critic, target_critic = eval_var(m, [m.C_source_real, m.C_target_real], f=grid_feed)\n",
    "    animate.source_contour_hdl = source_ax.contour(source_grid[0], source_grid[1],\n",
    "                                            source_critic.reshape(source_grid[0].shape), 20)\n",
    "    animate.target_contour_hdl = target_ax.contour(target_grid[0], target_grid[1],\n",
    "                                            target_critic.reshape(target_grid[0].shape), 20)\n",
    "\n",
    "    source_predictions, target_predictions, source_critic_grid, target_critic_grid = [], [], [], []\n",
    "    for epoch in range(total_steps):\n",
    "        if epoch % step_size == 0:\n",
    "            print('Recording epoch %d' % epoch)\n",
    "            predictions_of_source, predictions_of_target = eval_var(m, [m.F_source, m.G_target], f=data_feed)\n",
    "            source_critic, target_critic = eval_var(m, [m.C_source_real, m.C_target_real], f=grid_feed)\n",
    "            \n",
    "            source_predictions.append(predictions_of_source)\n",
    "            target_predictions.append(predictions_of_target)\n",
    "            source_critic_grid.append(source_critic.reshape(source_grid[0].shape))\n",
    "            target_critic_grid.append(target_critic.reshape(target_grid[0].shape))\n",
    "\n",
    "        try: translator_loss = m._global_step(0)\n",
    "        except ValueError:\n",
    "            print(\"Value Error!\")\n",
    "            break\n",
    "\n",
    "    # animation function. This is called sequentially\n",
    "    def draw_frame(i):\n",
    "        source_prediction, target_prediction = source_predictions[i], target_predictions[i]\n",
    "        source_critic, target_critic = source_critic_grid[i], target_critic_grid[i]\n",
    "        source_predictions_hdl.set_data(*columns(source_prediction))\n",
    "        target_predictions_hdl.set_data(*columns(target_prediction))\n",
    "        \n",
    "        #source_countour_hdl.collections.set_data(source_grid[0], source_grid[1], source_critic)\n",
    "        #target_countour_hdl.collections.set_data(target_grid[0], target_grid[1], target_critic)\n",
    "        #global source_contour_hdl, target_contour_hdl\n",
    "        for c in animate.source_contour_hdl.collections: c.remove()\n",
    "        for c in animate.target_contour_hdl.collections: c.remove()\n",
    "        animate.source_contour_hdl = source_ax.contour(source_grid[0], source_grid[1], source_critic, 20)\n",
    "        animate.target_contour_hdl = target_ax.contour(target_grid[0], target_grid[1], target_critic, 20)\n",
    "\n",
    "        return source_predictions_hdl, target_predictions_hdl\n",
    "    \n",
    "    # call the animator. blit=True means only re-draw the parts that have changed.    \n",
    "    anim = animation.FuncAnimation(fig, draw_frame, frames=int(np.floor(epoch/step_size)),\n",
    "                                   interval=interval, blit=True)\n",
    "    return (source_predictions, target_predictions, source_critic_grid, target_critic_grid), anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = np.random.normal(1, 0.01, 10000)\n",
    "T = np.random.uniform(0, 2*np.pi, 10000)\n",
    "X = R * np.cos(T)\n",
    "Y = R * np.sin(T)\n",
    "source = np.array([X, Y]).T\n",
    "\n",
    "desired_map = np.array([[0.2, 0], [0, 4]])\n",
    "desired_bias = np.array([1, 3])\n",
    "\n",
    "target = np.matmul(source, desired_map) + desired_bias\n",
    "source_paired, source_unpaired, source_test = source[:8000], np.empty((0, 2)), source[8000:]\n",
    "target_paired, target_unpaired, target_test = target[:8000], np.empty((0, 2)), target[8000:]\n",
    "source_data = map(lambda d: pd.DataFrame(d), [source_paired, source_unpaired, source_test])\n",
    "target_data = map(lambda d: pd.DataFrame(d), [target_paired, target_unpaired, target_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def redistribute(source_data, target_data, num_paired_out=3, seed=99):\n",
    "    source_paired, source_unpaired, source_test = source_data\n",
    "    target_paired, target_unpaired, target_test = target_data\n",
    "    index = list(range(len(source_paired) + len(source_unpaired)))\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.set_state(np.random.RandomState(seed).get_state())\n",
    "    np.random.shuffle(index)\n",
    "    source_tot = pd.concat([source_paired, source_unpaired])\n",
    "    target_tot = pd.concat([target_paired, target_unpaired])\n",
    "    return (\n",
    "        (source_tot.iloc[index[:num_paired_out]], source_tot.iloc[index[num_paired_out:]], source_test),\n",
    "        (target_tot.iloc[index[:num_paired_out]], target_tot.iloc[index[num_paired_out:]], target_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_limited, target_data_limited = redistribute(source_data, target_data, num_paired_out=2, seed=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.872010</td>\n",
       "      <td>-0.489025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>0.865383</td>\n",
       "      <td>0.504799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "408  -0.872010 -0.489025\n",
       "6444  0.865383  0.504799"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data_limited[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters are not necessarilly Optimal.\n",
    "def translator_learning_rate(step): return tf.train.piecewise_constant(step, [2500, 4000], [1e-2, 5e-4, 1e-5])\n",
    "OPTIONS = {\n",
    "    'num_critic_hidden_layers': 3,\n",
    "    'num_translator_hidden_layers': 0,\n",
    "    'network_activation': tfc.leaky_relu,\n",
    "    'max_global_epochs': [3500],\n",
    "    'print_anything': True,\n",
    "    'train_dropout_keep_prob': 1.0,\n",
    "    'use_batch_norm': False,\n",
    "    'adversarial_loss_multipliers': [2],\n",
    "    'cycle_loss_multipliers': [2],\n",
    "    'euc_dist_T_loss_multipliers': [10],\n",
    "    'euc_dist_S_loss_multipliers': [10],\n",
    "    'dev_size': 0.0,\n",
    "    'translator_learning_rate': translator_learning_rate,\n",
    "    'max_global_patiences': [500],\n",
    "    'batch_size': 10,\n",
    "    'num_translator_hidden_layers': 0,\n",
    "    'gradient_loss_multipliers': [3],\n",
    "    'max_critic_epochs': [5], #7, to vary\n",
    "    'max_translator_epochs': [1],\n",
    "    'min_global_epochs':0,\n",
    "    'L2_regularization_penalties': [0],\n",
    "    'critic_hidden_dim': 500,\n",
    "    'config': tf.ConfigProto(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/scratch/mmd/project_run_files/modality_translation/nan_debugging/save_every_batch', False)\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_translator/S_to_T/translator_layer/weights:0 is illegal; using TRANSLATOR_WGAN_translator/S_to_T/translator_layer/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_translator/S_to_T/translator_layer/bias:0 is illegal; using TRANSLATOR_WGAN_translator/S_to_T/translator_layer/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_translator/T_to_S/translator_layer/weights:0 is illegal; using TRANSLATOR_WGAN_translator/T_to_S/translator_layer/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_translator/T_to_S/translator_layer/bias:0 is illegal; using TRANSLATOR_WGAN_translator/T_to_S/translator_layer/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_0/weights:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_0/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_0/bias:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_0/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_1/weights:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_1/bias:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_2/weights:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/layer_2/bias:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/layer_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/output_layer/weights:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/output_layer/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/S_critic/output_layer/bias:0 is illegal; using TRANSLATOR_WGAN_critic/S_critic/output_layer/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_0/weights:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_0/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_0/bias:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_0/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_1/weights:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_1/bias:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_2/weights:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/layer_2/bias:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/layer_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/output_layer/weights:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/output_layer/weights_0 instead.\n",
      "INFO:tensorflow:Summary name TRANSLATOR_WGAN_critic/T_critic/output_layer/bias:0 is illegal; using TRANSLATOR_WGAN_critic/T_critic/output_layer/bias_0 instead.\n",
      "|     0     |  0.00s  |train, random_initialization|  5.89e+00   |    7.55e+01     |      3.25e+00       |      2.67e+00       |   1.94e+00    |    6.06e+01    |    2.27e+03    |        7.37e-02         |  8.27e+00  |      5.97e-01      |      1.77e+00      |          -7.37e-02          |\n",
      "|     0     |  0.00s  |dev, random_initialization|     nan     |       nan       |         nan         |         nan         |      nan      |      nan       |      nan       |           nan           |    nan     |        nan         |        nan         |             nan             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "two_paired = build_model(\n",
    "    source_data_limited,\n",
    "    target_data_limited,\n",
    "    model_name = 'test_run',\n",
    "    opts=OPTIONS,\n",
    "    joint=True\n",
    ")\n",
    "two_paired.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
